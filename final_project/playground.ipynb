{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neccessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "CLEAN_DATAFILE = \"BDP_CLEAN.csv\"\n",
    "df = pd.read_csv(CLEAN_DATAFILE)\n",
    "\n",
    "# lets drop the columns we dont want to predict on\n",
    "# these columns are only for identification\n",
    "drop_columns = ['Ticker', 'Rating Date', 'Fiscal Year']\n",
    "y_variable = \"RTG_SP_LT_LC_ISSUER_CREDIT\"\n",
    "df = df.drop(columns=drop_columns)\n",
    "x = df.drop(columns=[y_variable])\n",
    "y = df[y_variable]\n",
    "\n",
    "# within the x variables there are 2 columns that are categorical data\n",
    "# lets one hot encode the categorical data\n",
    "x = pd.get_dummies(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I am using this file to run other classification models in parallel with the models running in models.ipynb because the notebook won't run multiple code blocks at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxliu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n estimators:    200.000000\n",
      "Best learning rate:   0.250000\n"
     ]
    }
   ],
   "source": [
    "# this is adaboost\n",
    "\n",
    "# find the best parameters first\n",
    "kFold = 5\n",
    "param_grid = {'n_estimators': np.arange(200, 800, 100),\n",
    "                'learning_rate': np.arange(0.25, 1.25, 0.25)}\n",
    "adaboost_grid = GridSearchCV(AdaBoostClassifier(), param_grid, cv=kFold)\n",
    "\n",
    "# test using training data\n",
    "adaboost_grid.fit(x_train, y_train)\n",
    "best_n = adaboost_grid.best_params_['n_estimators']\n",
    "best_l = adaboost_grid.best_params_['learning_rate']\n",
    "\n",
    "print(\"Best n estimators:    %f\" % best_n)\n",
    "print(\"Best learning rate:   %f\" % best_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AdaBoost on test set: 0.115449\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy of the model on the test set\n",
    "adaboost_score = adaboost_grid.score(x_test, y_test)\n",
    "print(\"Accuracy of AdaBoost on test set: %f\" % adaboost_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxliu/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/maxliu/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/maxliu/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/maxliu/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/maxliu/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/maxliu/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/maxliu/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 5.30855756,  7.97637382, 10.55586929, 13.19462719, 15.8273417 ,\n",
       "        18.47492461,  5.26933699,  7.90738482, 10.56902876, 13.17866931,\n",
       "        15.85375681, 18.47049475,  5.26585355,  7.90462942, 10.51354742,\n",
       "        13.15230699, 15.79740324, 18.43070908,  5.27188425,  7.90415726,\n",
       "        10.52476482, 13.16258807, 15.80681472, 18.42431593]),\n",
       " 'mean_score_time': array([0.09678984, 0.14191236, 0.1877419 , 0.23458762, 0.27994242,\n",
       "        0.32697878, 0.09488301, 0.14073081, 0.18692408, 0.23406048,\n",
       "        0.27937417, 0.32469907, 0.09395733, 0.14001832, 0.18686867,\n",
       "        0.23262496, 0.27991014, 0.32338586, 0.09347868, 0.14003272,\n",
       "        0.18518262, 0.23198638, 0.28086324, 0.3245091 ]),\n",
       " 'mean_test_score': array([0.15239822, 0.14654211, 0.13720022, 0.13148355, 0.12841606,\n",
       "        0.12576687, 0.14054657, 0.132599  , 0.12757948, 0.12716118,\n",
       "        0.12674289, 0.12506972, 0.13873397, 0.14138316, 0.13984941,\n",
       "        0.1366425 , 0.13650307, 0.13552705, 0.13775795, 0.13775795,\n",
       "        0.13775795, 0.13775795, 0.13775795, 0.13775795]),\n",
       " 'mean_train_score': array([0.16546291, 0.16034924, 0.15480487, 0.15229514, 0.14494072,\n",
       "        0.14278297, 0.15073075, 0.14250491, 0.14044689, 0.137524  ,\n",
       "        0.13846606, 0.13643746, 0.15170548, 0.15278123, 0.15354977,\n",
       "        0.15131569, 0.15016507, 0.15020015, 0.14270668, 0.14270668,\n",
       "        0.14270668, 0.14270668, 0.14270668, 0.14270668]),\n",
       " 'param_learning_rate': masked_array(data=[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0,\n",
       "                    1.0, 1.0, 1.0, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[200, 300, 400, 500, 600, 700, 200, 300, 400, 500, 600,\n",
       "                    700, 200, 300, 400, 500, 600, 700, 200, 300, 400, 500,\n",
       "                    600, 700],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.25, 'n_estimators': 200},\n",
       "  {'learning_rate': 0.25, 'n_estimators': 300},\n",
       "  {'learning_rate': 0.25, 'n_estimators': 400},\n",
       "  {'learning_rate': 0.25, 'n_estimators': 500},\n",
       "  {'learning_rate': 0.25, 'n_estimators': 600},\n",
       "  {'learning_rate': 0.25, 'n_estimators': 700},\n",
       "  {'learning_rate': 0.5, 'n_estimators': 200},\n",
       "  {'learning_rate': 0.5, 'n_estimators': 300},\n",
       "  {'learning_rate': 0.5, 'n_estimators': 400},\n",
       "  {'learning_rate': 0.5, 'n_estimators': 500},\n",
       "  {'learning_rate': 0.5, 'n_estimators': 600},\n",
       "  {'learning_rate': 0.5, 'n_estimators': 700},\n",
       "  {'learning_rate': 0.75, 'n_estimators': 200},\n",
       "  {'learning_rate': 0.75, 'n_estimators': 300},\n",
       "  {'learning_rate': 0.75, 'n_estimators': 400},\n",
       "  {'learning_rate': 0.75, 'n_estimators': 500},\n",
       "  {'learning_rate': 0.75, 'n_estimators': 600},\n",
       "  {'learning_rate': 0.75, 'n_estimators': 700},\n",
       "  {'learning_rate': 1.0, 'n_estimators': 200},\n",
       "  {'learning_rate': 1.0, 'n_estimators': 300},\n",
       "  {'learning_rate': 1.0, 'n_estimators': 400},\n",
       "  {'learning_rate': 1.0, 'n_estimators': 500},\n",
       "  {'learning_rate': 1.0, 'n_estimators': 600},\n",
       "  {'learning_rate': 1.0, 'n_estimators': 700}],\n",
       " 'rank_test_score': array([ 1,  2, 13, 18, 19, 23,  4, 17, 20, 21, 22, 24,  6,  3,  5, 14, 15,\n",
       "        16,  7,  7,  7,  7,  7,  7], dtype=int32),\n",
       " 'split0_test_score': array([0.13001383, 0.14384509, 0.13485477, 0.11894882, 0.11341632,\n",
       "        0.12448133, 0.13070539, 0.13001383, 0.12793914, 0.13278008,\n",
       "        0.12448133, 0.11687414, 0.13969571, 0.1417704 , 0.13762102,\n",
       "        0.12033195, 0.12378976, 0.11618257, 0.11964039, 0.11964039,\n",
       "        0.11964039, 0.11964039, 0.11964039, 0.11964039]),\n",
       " 'split0_train_score': array([0.1535103 , 0.16241705, 0.14827104, 0.14634998, 0.14128537,\n",
       "        0.14652462, 0.16101991, 0.15228781, 0.15176388, 0.15665386,\n",
       "        0.15246245, 0.14233322, 0.16189312, 0.15822564, 0.15927349,\n",
       "        0.14879497, 0.14687391, 0.1480964 , 0.14233322, 0.14233322,\n",
       "        0.14233322, 0.14233322, 0.14233322, 0.14233322]),\n",
       " 'split1_test_score': array([0.15159944, 0.14742698, 0.13908206, 0.13282337, 0.12378303,\n",
       "        0.11891516, 0.14255911, 0.14394993, 0.14255911, 0.14255911,\n",
       "        0.14742698, 0.14603616, 0.13421419, 0.13004172, 0.12726008,\n",
       "        0.12100139, 0.12517385, 0.12656467, 0.13908206, 0.13908206,\n",
       "        0.13908206, 0.13908206, 0.13908206, 0.13908206]),\n",
       " 'split1_train_score': array([0.16742239, 0.16376003, 0.1667248 , 0.15852808, 0.15224974,\n",
       "        0.14509941, 0.14736659, 0.14998256, 0.15033136, 0.14841298,\n",
       "        0.16044646, 0.15678409, 0.14248343, 0.1355075 , 0.14143704,\n",
       "        0.14318103, 0.14335542, 0.14370422, 0.14004186, 0.14004186,\n",
       "        0.14004186, 0.14004186, 0.14004186, 0.14004186]),\n",
       " 'split2_test_score': array([0.15363128, 0.14385475, 0.13687151, 0.13896648, 0.13547486,\n",
       "        0.12709497, 0.1424581 , 0.12150838, 0.10614525, 0.10614525,\n",
       "        0.11243017, 0.1075419 , 0.14664804, 0.1452514 , 0.14594972,\n",
       "        0.15223464, 0.14664804, 0.14315642, 0.13128492, 0.13128492,\n",
       "        0.13128492, 0.13128492, 0.13128492, 0.13128492]),\n",
       " 'split2_train_score': array([0.16933798, 0.16324042, 0.16010453, 0.16707317, 0.15487805,\n",
       "        0.15905923, 0.15574913, 0.13867596, 0.11707317, 0.11533101,\n",
       "        0.12264808, 0.11655052, 0.16184669, 0.16114983, 0.16080139,\n",
       "        0.16045296, 0.16010453, 0.15766551, 0.14372822, 0.14372822,\n",
       "        0.14372822, 0.14372822, 0.14372822, 0.14372822]),\n",
       " 'split3_test_score': array([0.15314685, 0.15244755, 0.14685315, 0.13916084, 0.14125874,\n",
       "        0.13286713, 0.14055944, 0.11608392, 0.11678322, 0.11888112,\n",
       "        0.1041958 , 0.1048951 , 0.12937063, 0.14265734, 0.14055944,\n",
       "        0.14475524, 0.14195804, 0.14405594, 0.15104895, 0.15104895,\n",
       "        0.15104895, 0.15104895, 0.15104895, 0.15104895]),\n",
       " 'split3_train_score': array([0.16353187, 0.16022292, 0.15430164, 0.15186346, 0.14123999,\n",
       "        0.13218391, 0.14280738, 0.1220829 , 0.12434692, 0.11459422,\n",
       "        0.10484152, 0.10518983, 0.14489725, 0.16179032, 0.15935214,\n",
       "        0.16074538, 0.15604319, 0.15447579, 0.14332985, 0.14332985,\n",
       "        0.14332985, 0.14332985, 0.14332985, 0.14332985]),\n",
       " 'split4_test_score': array([0.17391304, 0.14516129, 0.128331  , 0.12762973, 0.128331  ,\n",
       "        0.12552595, 0.14656381, 0.15147265, 0.14446003, 0.13534362,\n",
       "        0.14516129, 0.15007013, 0.14375877, 0.14726508, 0.14796634,\n",
       "        0.14516129, 0.14516129, 0.14796634, 0.14796634, 0.14796634,\n",
       "        0.14796634, 0.14796634, 0.14796634, 0.14796634]),\n",
       " 'split4_train_score': array([0.17351201, 0.15210581, 0.14462235, 0.13766098, 0.13505047,\n",
       "        0.13104769, 0.14671076, 0.1494953 , 0.15871911, 0.15262792,\n",
       "        0.15193178, 0.16132962, 0.14740689, 0.14723286, 0.14688479,\n",
       "        0.14340411, 0.14444831, 0.14705882, 0.14410024, 0.14410024,\n",
       "        0.14410024, 0.14410024, 0.14410024, 0.14410024]),\n",
       " 'std_fit_time': array([0.03525516, 0.05825881, 0.03267613, 0.05328082, 0.07788645,\n",
       "        0.07563264, 0.02171955, 0.0257851 , 0.07074759, 0.05871707,\n",
       "        0.08604067, 0.07388241, 0.02257406, 0.04215641, 0.05104714,\n",
       "        0.04145109, 0.03984976, 0.08619102, 0.01973598, 0.03082046,\n",
       "        0.03650813, 0.05853452, 0.06221164, 0.07547963]),\n",
       " 'std_score_time': array([0.00093943, 0.0027964 , 0.00154963, 0.0015302 , 0.00379709,\n",
       "        0.00519535, 0.00188144, 0.00139398, 0.00322351, 0.00412494,\n",
       "        0.00408656, 0.00405995, 0.00129761, 0.00208706, 0.00307573,\n",
       "        0.00230167, 0.00189295, 0.00318371, 0.00092925, 0.00156011,\n",
       "        0.0020487 , 0.0039439 , 0.00325769, 0.00321467]),\n",
       " 'std_test_score': array([0.01391407, 0.0032246 , 0.00600499, 0.00761072, 0.00961779,\n",
       "        0.00449015, 0.00531668, 0.01330218, 0.01471887, 0.01300276,\n",
       "        0.01721996, 0.01919501, 0.00626808, 0.00600089, 0.00730818,\n",
       "        0.01337095, 0.00998547, 0.01218376, 0.01143851, 0.01143851,\n",
       "        0.01143851, 0.01143851, 0.01143851, 0.01143851]),\n",
       " 'std_train_score': array([0.00678583, 0.00429507, 0.00795989, 0.01006906, 0.00744374,\n",
       "        0.01033769, 0.00665295, 0.0112446 , 0.01652387, 0.0186062 ,\n",
       "        0.02117159, 0.02209194, 0.00844403, 0.01009955, 0.00787597,\n",
       "        0.00784256, 0.00668176, 0.00510888, 0.00145703, 0.00145703,\n",
       "        0.00145703, 0.00145703, 0.00145703, 0.00145703])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = adaboost_grid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
